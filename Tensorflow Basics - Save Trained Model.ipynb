{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkpoint and reuse trained model with tf.train.Saver 's stored variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot') # use this plot style\n",
    "%matplotlib inline\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('Tensorflow version ' + tf.VERSION)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Numpy version ' + np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to model\n",
    "y = a * x^2 + b * x + c  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## preparing the data\n",
    "\n",
    "# Let's generate 1000 random samples\n",
    "np.random.seed(41)\n",
    "pool = np.random.rand(1000,1).astype(np.float32)\n",
    "\n",
    "# Shuffle the samples\n",
    "np.random.shuffle(pool)\n",
    "\n",
    "# sample size of 15%\n",
    "sample = int(1000*0.15)\n",
    "\n",
    "# test and train data\n",
    "test_x = pool[:sample]\n",
    "train_x = pool[sample:]\n",
    "\n",
    "print('Testing data points: ' + str(test_x.shape))\n",
    "print('Training data points: ' + str(train_x.shape))\n",
    "\n",
    "# Let's compute the ouput using 2 for a, 3 for b, and 5 for c\n",
    "test_y = 2.0 * test_x**2 + 3.0 * test_x + 5\n",
    "train_y = 2.0 * train_x**2 + 3.0 * train_x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\":train_x[:,0], \"y\":train_y[:,0]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"x\", y=\"y\", figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model your Graph\n",
    "\n",
    "Start to use W (for weight) and b (for bias) when setting up your variables. Aside from adding your ReLU activation function, it is a good idea to use Tensorflow's **matrix multiplication function (matmul)** as shown below.\n",
    "\n",
    "> The ? in the shape output just means it can be of any shape.\n",
    "\n",
    "For the shape parameter, you can think of it like this...\n",
    "> shape = [how many data points do you have, how many features does each data point have]\n",
    "\n",
    "For this lesson since we are doing a simple regression, we only have one feature (x). We use the **None** keyword so that we are not restricted on the number of samples to feed our model. This will become more important when you learn about training using batches on a future lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can adjust the number of neurons in the hidden layer here\n",
    "hidden_size = 1\n",
    "\n",
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 1], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name='y')\n",
    "\n",
    "print(\"shape of x and y:\")\n",
    "print(x.get_shape(),y.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# create your first hidden layer!\n",
    "# tf.truncated_normal([how many samples do you have, size of output layer])\n",
    "W1 = tf.Variable(tf.truncated_normal([1, hidden_size], mean=0.1, stddev=0.01, seed=seed), name=\"w1\")\n",
    "\n",
    "# tf.truncated_normal([size of output layer])\n",
    "b1 = tf.Variable(tf.zeros([hidden_size]), name=\"b1\")\n",
    "\n",
    "# shape of h1 = [size of your samples, size of output layer]\n",
    "h1 = tf.nn.relu(tf.matmul(x, W1) + b1, name=\"h1\")\n",
    "\n",
    "print(\"shape of hidden layer:\")\n",
    "print(h1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, 1], mean=0.1, stddev=0.01, seed=seed), name=\"w\")\n",
    "b = tf.Variable(tf.zeros([1]), name=\"b\")\n",
    "\n",
    "# note that the input comes from our hidden layer h1\n",
    "pred = tf.nn.relu(tf.matmul(h1, W) + b)\n",
    "\n",
    "print(\"shape of output layer:\")\n",
    "print(pred.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(pred-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.09)\n",
    "train = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Good is Your model?\n",
    "Set up the following variables to calculate the accuracy rate of your model. You will do that shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.round(pred), tf.round(y))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Time!\n",
    "The best score I was able to obtain was a ~90% accuracy using a LR of 0.09 and iterating 250 times. I tried different learning rates and iterations but I was having a hard time getting past the 89 mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "t=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #train the model\n",
    "    train_data = {x:train_x, y:train_y}\n",
    "    test_data = {x:test_x, y:test_y}\n",
    "    print(W1.eval(), W.eval())\n",
    "    for step in range(1000):\n",
    "        train_loss, train_pred = sess.run([loss, train], feed_dict=train_data)\n",
    "        if step%100==0:\n",
    "            acc = sess.run(accuracy, feed_dict=train_data)\n",
    "            t.append((step, train_loss))\n",
    "            print(\"Training loss at step %d: %f  accuracy: %f\" % (step, train_loss, acc))     \n",
    "    \n",
    "    print(\"Accuracy on the Training Set:\", accuracy.eval(train_data) )\n",
    "    print(\"Accuracy on the Test Set:\", accuracy.eval(test_data) )\n",
    "    print(W1.eval(), W.eval())\n",
    "    \n",
    "    #persist model into file\n",
    "    save = tf.train.Saver()\n",
    "    save_path = save.save(sess, 'checkpoint_models/lesson7.ckpt')\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_loss = pd.DataFrame(t, columns=['step', 'train_loss']) \n",
    "df_loss.plot(x='step', y='train_loss', figsize=(15,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use checkpoint model to restore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rsaver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    rsaver.restore(sess, 'checkpoint_models/lesson7.ckpt')\n",
    "    test_data = {x:test_x, y:test_y}\n",
    "    print(\"Accuracy on the Test Set:\", accuracy.eval(test_data) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
